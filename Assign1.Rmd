---
title: "Assignment"
output: html_document
---

### Part (I): Load Data

```{r}
library(RWeka)
library(caret)
df <- read.csv("sonar.all-data")

```

### Part (II): Evaluate Decision Tree model
#### A model is created using J48 method from the RWeka library which implements the C4.5 algorithm for decision trees. Since in this part we want to evaluate the model once without cross validation and once with 10-folds cross validation on the same training dataset, the evaluate method could be used with specifying the numFolds and outputting a summary of the evaluation metrics as well as the confusion matrix.

```{r}
sonar_j48 <- J48(R ~ ., data = df)


evaluate_Weka_classifier(sonar_j48, numFolds = 0, complexity = FALSE, 
                                     class = TRUE)

evaluate_Weka_classifier(sonar_j48, numFolds = 10, complexity = FALSE, 
                                     class = TRUE)

```

### Part (III):
#### Here we want to compare the performance of the different classifiers. after each classifier we print the Sensitivity which is equal to the recall of the first class, Positive Predictive Value ois the Precision


```{r}
split=0.80
trainIndex <- createDataPartition(df$R, p=split, list=FALSE)
data_train <- df[ trainIndex,]
data_test <- df[-trainIndex,]
train_control <- trainControl(method="cv", number=10)
model <- train(R~., data=data_train, trControl=train_control, method="rf")
#print(model)

p <- predict(model,newdata = data_test[,1:60])
t <- table(p , data_test[,61])
cm <- confusionMatrix(t)
cm
precision <- cm$byClass['Pos Pred Value'] 
precision
recall <- cm$byClass['Sensitivity']
recall
f_measure <- 2 * ((precision * recall) / (precision + recall))
f_measure
```



```{r warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
split=0.80
trainIndex <- createDataPartition(df$R, p=split, list=FALSE)
data_train <- df[ trainIndex,]
data_test <- df[-trainIndex,]
train_control <- trainControl(method="cv", number=10)
model <- train(R~., data=data_train, trControl=train_control, method="nb")
p <- predict(model,newdata = data_test[,1:60])
t <- table(p , data_test[,61])
cm <- confusionMatrix(t)
cm
precision <- cm$byClass['Pos Pred Value'] 
precision
recall <- cm$byClass['Sensitivity']
recall
f_measure <- 2 * ((precision * recall) / (precision + recall))
f_measure
```

```{r warning=FALSE, message=FALSE }
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
split=0.80
trainIndex <- createDataPartition(df$R, p=split, list=FALSE)
data_train <- df[ trainIndex,]
data_test <- df[-trainIndex,]
train_control <- trainControl(method="cv", number=10)
model <- train(R~., data=data_train, trControl=train_control, method="nnet")
p <- predict(model,newdata = data_test[,1:60])
t <- table(p , data_test[,61])
cm <- confusionMatrix(t)
cm
precision <- cm$byClass['Pos Pred Value'] 
precision
recall <- cm$byClass['Sensitivity']
recall
f_measure <- 2 * ((precision * recall) / (precision + recall))
f_measure
```

```{r warning=FALSE, message=FALSE }
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
split=0.80
trainIndex <- createDataPartition(df$R, p=split, list=FALSE)
data_train <- df[ trainIndex,]
data_test <- df[-trainIndex,]
train_control <- trainControl(method="cv", number=10)
model <- train(R~., data=data_train, trControl=train_control, method="svmLinear")
p <- predict(model,newdata = data_test[,1:60])
t <- table(p , data_test[,61])
cm <- confusionMatrix(t)
cm
precision <- cm$byClass['Pos Pred Value'] 
precision
recall <- cm$byClass['Sensitivity']
recall
f_measure <- 2 * ((precision * recall) / (precision + recall))
f_measure
```


